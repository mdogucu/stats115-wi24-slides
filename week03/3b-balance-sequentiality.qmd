---
title: "Balance and Sequentiality in Bayesian Analyses"
author: "Dr. Mine Dogucu"
execute:
  echo: true
format: 
  revealjs:
    footer: "[stats115.com](https://stats115.com)"
    slide-number: true
    incremental: true
    theme: ["../templates/slide-style.scss"]
    logo: "https://www.stats115.com/img/logo.png"
    title-slide-attributes: 
      data-background-image: "https://stats115.com/img/logo.png"
      data-background-size: 5%
      data-background-position: 50% 85%
    include-after-body: "../templates/clean_title_page.html"
---

```{r}
#| echo: false
library(tidyverse)
library(bayesrules)
theme_set(theme_gray(base_size = 18))

## Code for facet_wrapped Beta-Binomial plots

### Plotting function
beta_binom_grid_plot <- function(data, likelihood = FALSE, posterior = FALSE){
  g <- ggplot(data, aes(x = pi, y = prior)) + 
    geom_line() + 
    geom_area(alpha = 0.5, aes(fill = "prior", x = pi, y = prior)) + 
    scale_fill_manual("", values = c(prior = "#f0e442", 
      `(scaled) likelihood` = "#0071b2", posterior = "#009e74"), breaks = c("prior", "(scaled) likelihood", "posterior")) + 
    labs(x = expression(pi), y = "density") + 
    theme(legend.position="bottom")
  
  if(likelihood == TRUE){
    g <- g + 
      geom_line(aes(x = pi, y = likelihood)) + 
      geom_area(alpha = 0.5, aes(fill = "(scaled) likelihood", x = pi, y = likelihood))
  }
  
  if(posterior == TRUE){
    g <- g + 
      geom_line(aes(x = pi, y = posterior)) + 
      geom_area(alpha = 0.5, aes(fill = "posterior", x = pi, y = posterior)) 
  }
  g
}


make_plot_data <- function(as, bs, ys, ns, labs_prior, labs_likelihood){
  ### Set up data to call in plot
  # Refinement parameter
  size <- 250
  
  # Model settings
  pi <- rep(seq(0,1,length=size), 9)
  
  # Prior parameters
  a <- rep(as, each = size*3)
  b <- rep(bs, each = size*3)

  # Data
  y <- rep(rep(ys, each = size), 3)
  n <- rep(rep(ns, each = size), 3)

  # Posterior parameters
  a_post <- y + a
  b_post <- n - y + b

  # Labels
  setting_prior      <- as.factor(rep(1:3, each = size*3))
  setting_likelihood <- as.factor(rep(rep(1:3, each = size), 3))
  levels(setting_prior)      <- labs_prior
  levels(setting_likelihood) <- labs_likelihood    

  # Prior, likelihood, posterior functions
  bfun1 <- function(x){dbinom(x = ys[1], size = ns[1], prob = x)}
  bfun2 <- function(x){dbinom(x = ys[2], size = ns[2], prob = x)}
  bfun3 <- function(x){dbinom(x = ys[3], size = ns[3], prob = x)}
  scale   <- rep(rep(c(integrate(bfun1, 0, 1)[[1]], integrate(bfun2, 0, 1)[[1]], integrate(bfun3, 0, 1)[[1]]), each = size), 3)
  prior      <- dbeta(x = pi, shape1 = a, shape2 = b)
  likelihood <- dbinom(x = y, size = n, prob = pi) / scale
  posterior  <- dbeta(x = pi, shape1 = a_post, shape2 = b_post)

  # Combine into data frame
  data.frame(setting_prior, setting_likelihood, pi, a, b, y, n, likelihood, prior, posterior)
}

plot_dat <- make_plot_data(
  as = c(5,1,14), bs = c(11,1,1), 
  ys = c(9,27,197), ns = c(20,60,438), 
  labs_prior = c("prior: Beta(5,11)", "prior: Beta(1,1)", "prior: Beta(14,1)"), 
  labs_likelihood = c("data: Y = 9 of n = 20", "data: Y = 27 of n = 60", "data: Y = 197 of n = 438"))

```


##

The notes for this lecture are derived from  [Chapter 4 of the Bayes Rules! book](https://www.bayesrulesbook.com/chapter-4)

# Balance in Bayesian Analyses


## Data Context

__Bechdel Test__

Alison Bechdel’s 1985 comic Dykes to Watch Out For has a strip called [The Rule](https://www.npr.org/templates/story/story.php?storyId=94202522?storyId=94202522) where a person states that they only go to a movie if it satisfies the
following three rules:
- the movie has to have at least two women in it;
- these two women talk to each other; and
- they talk about something besides a man.

This test is used for assessing movies in terms of representation of women. Even though there are three criteria, a movie either fails or passes the Bechdel test.



## Different Priors, Different Posteriors

Let $\pi$ be the the proportion of movies that pass the Bechdel test.

Below there are three different people with three different priors about $\pi$.

<table align = "center">
  <tr>
    <td>optimist</td>
    <td>clueless </td>
    <td>feminist </td>
  </tr>
  
  <tr>
    <td>Beta(14,1)</td>
    <td>Beta(1,1)</td>
    <td>Beta(5,11)</td>
  </tr>

</table>



Plot their priors.

## Priors

```{r}
#| echo: false
#| fig-align: center

optimist <- plot_beta(14, 1) +
  labs(title = "Optimist")

clueless <- plot_beta(1, 1) +
  labs(title = "Clueless")

feminist <- plot_beta(5, 11) +
  labs(title = "Feminist")

gridExtra::grid.arrange(optimist, clueless, feminist, ncol = 3)

```



## Vocabulary

__Informative prior:__ An informative prior reflects specific information about the unknown
variable with high certainty (ie. low variability).


__Vague (diffuse) prior:__

A vague or diffuse prior reflects little specific information about the unknown variable. A flat prior, which assigns equal prior plausibility to all possible values of the variable, is a special case.


## Data

- `library(bayesrules)` has `bechdel` data frame. Randomly select 20 movies from this dataset (`seed = 84735`).

- Based on observed data, update the posterior for all three people. 

- Calculate the summary statistics for the prior and the posterior for all three.

- Plot the prior, likelihood, and the posterior for all three.

- Explain the effect of different priors on the posterior.


##

```{r}
#| message: false
library(tidyverse)
library(bayesrules)
set.seed(84735)
```

. . .

```{r}
bechdel_sample <- sample_n(bechdel, 20)
```

. . .

```{r}
count(bechdel_sample, binary)
```


## The Optimist 

```{r}
summarize_beta_binomial(14, 1, y = 9, n = 20)
```


## The Optimist 


```{r}
#| fig-align: center
plot_beta_binomial(14, 1, y = 9, n = 20)
```



## The Clueless 

```{r}
#| fig-align: center
summarize_beta_binomial(1, 1, y = 9, n = 20)
```


## The Clueless 


```{r}
#| fig-align: center
plot_beta_binomial(1, 1, y = 9, n = 20)
```

## The Feminist 

```{r}
summarize_beta_binomial(5, 11, y = 9, n = 20)
```

## The Feminist


```{r}
#| fig-align: center
plot_beta_binomial(5, 11, y = 9, n = 20)
```

## Comparison 


```{r}
#| fig-align: center
#| echo: false

plot_dat_sub <- plot_dat %>% filter(y == 9) %>% mutate(setting_prior = factor(setting_prior, levels = c("prior: Beta(1,1)", "prior: Beta(5,11)", "prior: Beta(14,1)")))

g1 <- beta_binom_grid_plot(plot_dat_sub) + 
  facet_grid(~ setting_prior) + 
  theme(legend.position = "none")

g1 <- beta_binom_grid_plot(plot_dat_sub, likelihood = TRUE, posterior = TRUE) + 
  facet_grid( ~ setting_prior) +
  theme(legend.position = "bottom")

g1

```





## Different Data, Different Posteriors

Morteza, Nadide, and Ursula –  all share the optimistic Beta(14,1) prior for $\pi$ but each have access to different data. Morteza reviews movies from 1991. Nadide reviews movies from 2000 and Ursula reviews movies from 2013. How will the posterior distribution for each differ?


## Morteza's analysis

```{r}
bechdel_1991 <- filter(bechdel, year == 1991)
count(bechdel_1991, binary)


6/13
```


## Morteza's analysis

```{r}
#| fig-align: center
plot_beta_binomial(14, 1, y = 6, n = 13)
```


## Nadide's analysis

```{r}
bechdel_2000 <- filter(bechdel, year == 2000)
count(bechdel_2000, binary)

29/(34+29)
```



## Nadide's analysis

```{r}
#| fig-align: center
plot_beta_binomial(14, 1, y = 29, n = 63)
```


## Ursula's analysis

```{r}
bechdel_2013 <- filter(bechdel, year == 2013)
count(bechdel_2013, binary)

46/(53+46)
```


## Ursula's analysis

```{r}
#| fig-align: center
plot_beta_binomial(14, 1, y = 46, n = 99)

```


## Summary

```{r}
#| echo: false
#| message: false
### Plotting function
beta_binom_grid_plot <- function(data, likelihood = FALSE, posterior = FALSE){
  g <- ggplot(data, aes(x = pi, y = prior)) + 
    geom_line() + 
    geom_area(alpha = 0.5, aes(fill = "prior", x = pi, y = prior)) + 
    scale_fill_manual("", values = c(prior = "gold1", 
      `(scaled) likelihood` = "cyan2", posterior = "cyan4"), breaks = c("prior", "(scaled) likelihood", "posterior")) + 
    labs(x = expression(pi), y = "density") + 
    theme(legend.position="bottom")
  
  if(likelihood == TRUE){
    g <- g + 
      geom_line(aes(x = pi, y = likelihood)) + 
      geom_area(alpha = 0.5, aes(fill = "(scaled) likelihood", x = pi, y = likelihood))
  }
  
  if(posterior == TRUE){
    g <- g + 
      geom_line(aes(x = pi, y = posterior)) + 
      geom_area(alpha = 0.5, aes(fill = "posterior", x = pi, y = posterior)) 
  }
  g
}
make_plot_data <- function(as, bs, xs, ns, labs_prior, labs_likelihood){
  ### Set up data to call in plot
  # Refinement parameter
  size <- 250
  
  # Model settings
  pi <- rep(seq(0,1,length=size), 9)
  
  # Prior parameters
  a <- rep(as, each = size*3)
  b <- rep(bs, each = size*3)
  # Data
  x <- rep(rep(xs, each = size), 3)
  n <- rep(rep(ns, each = size), 3)
  # Posterior parameters
  a_post <- x + a
  b_post <- n - x + b
  # Labels
  setting_prior      <- as.factor(rep(1:3, each = size*3))
  setting_likelihood <- as.factor(rep(rep(1:3, each = size), 3))
  levels(setting_prior)      <- labs_prior
  levels(setting_likelihood) <- labs_likelihood    
  # Prior, likelihood, posterior functions
  bfun1 <- function(x){dbinom(x = xs[1], size = ns[1], prob = x)}
  bfun2 <- function(x){dbinom(x = xs[2], size = ns[2], prob = x)}
  bfun3 <- function(x){dbinom(x = xs[3], size = ns[3], prob = x)}
  scale   <- rep(rep(c(integrate(bfun1, 0, 1)[[1]], integrate(bfun2, 0, 1)[[1]], integrate(bfun3, 0, 1)[[1]]), each = size), 3)
  prior      <- dbeta(x = pi, shape1 = a, shape2 = b)
  likelihood <- dbinom(x = x, size = n, prob = pi) / scale
  posterior  <- dbeta(x = pi, shape1 = a_post, shape2 = b_post)
  # Combine into data frame
  data.frame(setting_prior, setting_likelihood, pi, a, b, x, n, likelihood, prior, posterior)
}
plot_dat <- make_plot_data(
  as = c(5,1,14), bs = c(11,1,1), 
  xs = c(6,29,46), ns = c(13,63,99), 
  labs_prior = c("prior: Beta(5,11)", "prior: Beta(1,1)", "prior: Beta(14,1)"), 
  labs_likelihood = c("data: Y = 6 of n = 13", "data: Y = 29 of n = 63", "data: Y = 46 of n = 99"))
```


```{r echo = FALSE, fig.align='center'}
#| echo: false
#| fig-align: center
plot_dat_new <- plot_dat |> 
  mutate(setting_prior = factor(setting_prior, 
                                levels = c("prior: Beta(14,1)", "prior: Beta(5,11)", "prior: Beta(1,1)")))
beta_binom_grid_plot(plot_dat_new, posterior = TRUE, likelihood = TRUE) + 
  facet_grid(setting_prior ~ setting_likelihood) +
  theme(text = element_text(size=17)) 
```


# Sequentiality in Bayesian Analyses


## Sequential Analysis 

In a sequential Bayesian analysis, a posterior model is updated incrementally as more data comes in.  With the introduction of each new piece of data, the previous posterior model reflecting our understanding prior to observing this data becomes the new prior model.

## Let's time travel to the end of 1970

$\pi \sim Beta(14,1)$

. . .

```{r}
bechdel |> 
  filter(year == 1970) 
```


## The Posterior

```{r}
summarize_beta_binomial(14, 1, y = 1, n = 1)
```


## At the end of 1971

$\pi \sim Beta(15,1)$

. . .

```{r}
bechdel |> 
  filter(year == 1971) 
```


## The Posterior

```{r}
summarize_beta_binomial(15, 1, y = 0, n = 5)
```



## At the end of 1972

$\pi \sim Beta(15,6)$

. . .

```{r}
bechdel |> 
  filter(year == 1972) 
```


## The Posterior

```{r}
summarize_beta_binomial(15, 6, y = 1, n = 3)
```

##

<center>

| Time                | Data         | Model       |
|---------------------|--------------|-------------|
| before the analysis | NA           | Beta(14,1)  |
| at the end of 1970  | Y = 1, n = 1 | Beta(15,1)  |
| at the end of 1971  | Y = 0, n = 5 | Beta(15, 6) |
| at the end of 1972  | Y = 1, n = 3 | Beta(16,8)  |

<\center>


<center>

## Data Order Invariance

| Time                | Data         | Model      |
|---------------------|--------------|------------|
| before the analysis | NA           | Beta(14,1) |
| 1972                | Y = 1, n = 3 | Beta(15,3) |
| 1971                | Y = 0, n = 5 | Beta(15,8) |
| 1970                | Y = 1, n = 1 | Beta(16,8) |

<\center>




## What if we observed all the data at once?

<center>


| Time                | Data         | Model      |
|---------------------|--------------|------------|
| before the analysis | NA           | Beta(14,1) |
| 1970  | Y = 1, n = 1 |            |
|1971  | Y = 0, n = 5 |            |
|1972  | Y = 1, n = 3 |            |
| Total               | Y = 2, n = 9 |            |

<\center>

##

```{r}
summarize_beta_binomial(14, 1, y = 2, n = 9)
```

##

Let $\theta$ be any parameter of interest with prior pdf $f(\theta)$.  Then a __sequential analysis__ in which we _first_ observe a data point $y_1$ and _then_ a second data point $y_2$ will produce the same posterior model of $\theta$ as if we _first_ observe $y_2$ and *then* $y_1$: 

$$f(\theta | y_1,y_2) = f(\theta|y_2,y_1)\;.$$

Similarly, the posterior model is invariant to whether we observe the data _all at once_ or _sequentially_.


